{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Python version 2.7.13 (default, Dec 20 2016 23:09:15)\nSparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/lib/spark/\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]= \"/home/cloudera/anaconda2/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]= \"/home/cloudera/anaconda2/bin/python\"\n",
    "os.environ[\"SPARK_YARN_USER_ENV\"]= \"/home/cloudera/anaconda2/bin/python\"\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.1-src.zip'))\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))\n",
    "\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= sc.textFile(\"/user/cloudera/kaggle/orders\").map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x.filter(lambda x: x[2]=='test').map(lambda x: x[1]).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorizationModel.load(sc, \"/user/cloudera/kaggle/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=1, product=13176, rating=0.6833920201082382),\n Rating(user=1, product=12341, rating=0.2606711224255599),\n Rating(user=1, product=6184, rating=0.25304948680000483),\n Rating(user=1, product=43352, rating=0.23523993177616165),\n Rating(user=1, product=21903, rating=0.21333270362711204),\n Rating(user=1, product=21137, rating=0.1810016485532501),\n Rating(user=1, product=196, rating=0.16125479473361332),\n Rating(user=1, product=42265, rating=0.1545010261115591),\n Rating(user=1, product=35561, rating=0.1408376275833716),\n Rating(user=1, product=39275, rating=0.13990913621452966)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recommendProducts(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_prior =  sc.textFile(\"/user/cloudera/kaggle/order_product_prior_joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "j= joined_prior.map(lambda x : x.split(',')).map(lambda x: (x[1], x[7])).map(lambda x : (x[0], len(x[1].split(' ')))).\\\n",
    "    reduceByKey(lambda x, y : x+y).map(lambda x : x[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "print reduce(lambda x,y : x+y, j )/len(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = test.map(lambda x : int(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def recommend(list):\n",
    "    start_time = time.time()\n",
    "    i=0\n",
    "    x= []\n",
    "    for val in test_list:\n",
    "        if (i%10 == 0):\n",
    "            print \"recommendor count has crossed %d and time lapsed %d secs\" %(i, time.time() - start_time)\n",
    "        x.append(model.recommendProducts(val,2))\n",
    "        if(i>30):\n",
    "            break\n",
    "        i= i+1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendor count has crossed 0 and lime lapsed 0 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendor count has crossed 10 and lime lapsed 44 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendor count has crossed 20 and lime lapsed 61 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendor count has crossed 30 and lime lapsed 76 secs\n"
     ]
    }
   ],
   "source": [
    "x= recommend(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### it seems like for 10 prediction approximate 20 seconds of time is required \n",
    "##### this implies 2 sec per user hence for 75000 rows of test set it might take 150000 secs \n",
    "##### This might require approx two day to complete that is not possible with the personal machine \n",
    "##### Only thing is that once we have the list of predictions we can convert it to rdd and set it into right format of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since the recommemdProduct function takes a lot of time we may think of other methods to predict \n",
    "##### Lets take in predict_all function to find the output rating of user and products of interest.\n",
    "##### All we need is to find out the right combination of user and product to get the rating.\n",
    "##### As cartegion multiplication of the all products with all test users will lead to large data set.\n",
    "##### so product which user have purchased earlier can be used or can use the aisles that user have considered with rating for all products under the aisles \n",
    "##### we can use aisles data set as broadcast variable and limit the no of product to get the rating for the users  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisles = sc.textFile(\"file:///home/cloudera/Desktop/kaggle/aisles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prod_prio_inter = sc.textFile(\"/user/cloudera/kaggle/order_prior_inter\").map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[15] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_prod.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_prod.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}